{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnvSpec(id='CartPoleSwingUp', entry_point='myCartpoleF_SwingUp:CartPoleSwingUp', reward_threshold=-38.0, nondeterministic=False, max_episode_steps=24000, order_enforce=True, disable_env_checker=False, kwargs={}, namespace=None, name='CartPoleSwingUp', version=None, additional_wrappers=(), vector_entry_point=None)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from scipy.integrate import solve_ivp\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "import scipy\n",
    "\n",
    "import sys\n",
    "import gymnasium as gym\n",
    "import time\n",
    "import signal\n",
    "\n",
    "# 定义环境的相关设置\n",
    "balance_time = 240\n",
    "h_in = 1 / 100\n",
    "\n",
    "# 注册和创建自定义环境\n",
    "CartPoleSwingUp = gym.register(\n",
    "    id = 'CartPoleSwingUp',\n",
    "    entry_point = 'myCartpoleF_SwingUp:CartPoleSwingUp',  # 根据你的环境路径修改\n",
    "    reward_threshold = -40 * 0.95,\n",
    "    max_episode_steps = int(balance_time / h_in),\n",
    ")\n",
    "env = gym.make('CartPoleSwingUp', render_mode='human')\n",
    "print(gym.spec('CartPoleSwingUp'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建 NormalActionNoise 实例，用于在智能体的动作中加入噪声。具体的参数含义如下：\n",
    "\n",
    "mean = np.zeros(env.action_space.shape): 这里的 mean 是噪声的均值，np.zeros(env.action_space.shape) 表示均值为零，且它的维度与环境的动作空间 env.action_space.shape 相同。env.action_space.shape 表示动作空间的维度。\n",
    "\n",
    "sigma = 0.1 * np.ones(env.action_space.shape): 这里的 sigma 是噪声的标准差，0.1 * np.ones(env.action_space.shape) 表示标准差是 0.1，并且与动作空间的维度相同。这样每个维度的噪声标准差都是 0.1。\n",
    "\n",
    "通过这种方式，动作中会加入一定的噪声，从而使得训练过程更加稳定，防止模型陷入局部最优解，增强探索性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建 DDPG 模型：\n",
    "\n",
    "'MlpPolicy': 选择了多层感知器（MLP）作为策略网络的结构。该网络用于从状态中输出动作。\n",
    "\n",
    "env: 环境对象，智能体将在该环境中进行训练。\n",
    "\n",
    "policy_kwargs = dict(net_arch=[400, 300]): 这个参数定义了策略网络的结构，net_arch=[400, 300] 表示策略网络有两层隐藏层，分别有 400 个神经元和 300 个神经元。policy_kwargs 是传递给策略网络构造函数的附加参数。\n",
    "\n",
    "verbose = 1: 这个参数设置了训练时的输出级别，verbose=1 表示打印训练过程中的信息。\n",
    "\n",
    "tensorboard_log = \"./ddpg_cartpole/\": 这个参数指定了 TensorBoard 日志的存储路径，用于后期可视化训练过程。\n",
    "\n",
    "action_noise=action_noise: 将前面创建的噪声对象 action_noise 传递给 DDPG 模型，用于在选择动作时加入噪声。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 63       |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 428      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 249      |\n",
      "|    critic_loss     | 1.08e+06 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 327      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 60       |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 565      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 369      |\n",
      "|    critic_loss     | 1.07e+06 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 464      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 58       |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 721      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 388      |\n",
      "|    critic_loss     | 1.07e+06 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 620      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 58       |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 848      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 483      |\n",
      "|    critic_loss     | 3.26e+06 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 747      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 57       |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 976      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 481      |\n",
      "|    critic_loss     | 1.45e+06 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 875      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 56       |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 1106     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 406      |\n",
      "|    critic_loss     | 1.4e+06  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 1005     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 55       |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 1222     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 632      |\n",
      "|    critic_loss     | 4.18e+06 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 1121     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 32       |\n",
      "|    fps             | 54       |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 1340     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 532      |\n",
      "|    critic_loss     | 1.9e+06  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 1239     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 36       |\n",
      "|    fps             | 54       |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 1460     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 737      |\n",
      "|    critic_loss     | 1.89e+06 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 1359     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 53       |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 1596     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 750      |\n",
      "|    critic_loss     | 2.48e+06 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 1495     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 44       |\n",
      "|    fps             | 53       |\n",
      "|    time_elapsed    | 31       |\n",
      "|    total_timesteps | 1699     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.07e+03 |\n",
      "|    critic_loss     | 4.22e+06 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 1598     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 48       |\n",
      "|    fps             | 53       |\n",
      "|    time_elapsed    | 33       |\n",
      "|    total_timesteps | 1803     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.1e+03  |\n",
      "|    critic_loss     | 4.15e+06 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 1702     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 52       |\n",
      "|    fps             | 53       |\n",
      "|    time_elapsed    | 36       |\n",
      "|    total_timesteps | 1926     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.22e+03 |\n",
      "|    critic_loss     | 3.48e+06 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 1825     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 56       |\n",
      "|    fps             | 53       |\n",
      "|    time_elapsed    | 38       |\n",
      "|    total_timesteps | 2047     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.47e+03 |\n",
      "|    critic_loss     | 4.52e+06 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 1946     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 60       |\n",
      "|    fps             | 52       |\n",
      "|    time_elapsed    | 40       |\n",
      "|    total_timesteps | 2168     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.71e+03 |\n",
      "|    critic_loss     | 2.7e+06  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 2067     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 64       |\n",
      "|    fps             | 52       |\n",
      "|    time_elapsed    | 43       |\n",
      "|    total_timesteps | 2295     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.72e+03 |\n",
      "|    critic_loss     | 3.74e+06 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 2194     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 68       |\n",
      "|    fps             | 52       |\n",
      "|    time_elapsed    | 45       |\n",
      "|    total_timesteps | 2412     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.09e+03 |\n",
      "|    critic_loss     | 2.2e+06  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 2311     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 72       |\n",
      "|    fps             | 52       |\n",
      "|    time_elapsed    | 48       |\n",
      "|    total_timesteps | 2536     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.06e+03 |\n",
      "|    critic_loss     | 2.08e+06 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 2435     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 76       |\n",
      "|    fps             | 52       |\n",
      "|    time_elapsed    | 50       |\n",
      "|    total_timesteps | 2660     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.86e+03 |\n",
      "|    critic_loss     | 4.27e+06 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 2559     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 80       |\n",
      "|    fps             | 52       |\n",
      "|    time_elapsed    | 53       |\n",
      "|    total_timesteps | 2787     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.21e+03 |\n",
      "|    critic_loss     | 3.62e+06 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 2686     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 84       |\n",
      "|    fps             | 52       |\n",
      "|    time_elapsed    | 56       |\n",
      "|    total_timesteps | 2917     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.2e+03  |\n",
      "|    critic_loss     | 4.26e+06 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 2816     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 88       |\n",
      "|    fps             | 51       |\n",
      "|    time_elapsed    | 58       |\n",
      "|    total_timesteps | 3047     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.23e+03 |\n",
      "|    critic_loss     | 3.17e+06 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 2946     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 92       |\n",
      "|    fps             | 51       |\n",
      "|    time_elapsed    | 60       |\n",
      "|    total_timesteps | 3155     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 5.45e+03 |\n",
      "|    critic_loss     | 2.95e+06 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 3054     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 96       |\n",
      "|    fps             | 51       |\n",
      "|    time_elapsed    | 63       |\n",
      "|    total_timesteps | 3285     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 5.3e+03  |\n",
      "|    critic_loss     | 3.13e+06 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 3184     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 51       |\n",
      "|    time_elapsed    | 66       |\n",
      "|    total_timesteps | 3413     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 6.26e+03 |\n",
      "|    critic_loss     | 3.98e+06 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 3312     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 104      |\n",
      "|    fps             | 51       |\n",
      "|    time_elapsed    | 68       |\n",
      "|    total_timesteps | 3531     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 5.72e+03 |\n",
      "|    critic_loss     | 4.58e+06 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 3430     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 108      |\n",
      "|    fps             | 51       |\n",
      "|    time_elapsed    | 71       |\n",
      "|    total_timesteps | 3661     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 5.29e+03 |\n",
      "|    critic_loss     | 3.67e+06 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 3560     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 112      |\n",
      "|    fps             | 51       |\n",
      "|    time_elapsed    | 73       |\n",
      "|    total_timesteps | 3788     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 8.19e+03 |\n",
      "|    critic_loss     | 5.16e+06 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 3687     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 116      |\n",
      "|    fps             | 51       |\n",
      "|    time_elapsed    | 75       |\n",
      "|    total_timesteps | 3904     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 8.62e+03 |\n",
      "|    critic_loss     | 2e+06    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 3803     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 120      |\n",
      "|    fps             | 51       |\n",
      "|    time_elapsed    | 78       |\n",
      "|    total_timesteps | 4022     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 8.36e+03 |\n",
      "|    critic_loss     | 3.8e+06  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 3921     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 124      |\n",
      "|    fps             | 51       |\n",
      "|    time_elapsed    | 80       |\n",
      "|    total_timesteps | 4138     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.1e+04  |\n",
      "|    critic_loss     | 3.44e+06 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 4037     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 128      |\n",
      "|    fps             | 51       |\n",
      "|    time_elapsed    | 83       |\n",
      "|    total_timesteps | 4260     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.06e+04 |\n",
      "|    critic_loss     | 4.71e+06 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 4159     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 132      |\n",
      "|    fps             | 51       |\n",
      "|    time_elapsed    | 85       |\n",
      "|    total_timesteps | 4391     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.23e+04 |\n",
      "|    critic_loss     | 2.66e+06 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 4290     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 136      |\n",
      "|    fps             | 51       |\n",
      "|    time_elapsed    | 87       |\n",
      "|    total_timesteps | 4512     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.27e+04 |\n",
      "|    critic_loss     | 4.11e+06 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 4411     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 140      |\n",
      "|    fps             | 51       |\n",
      "|    time_elapsed    | 90       |\n",
      "|    total_timesteps | 4640     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.14e+04 |\n",
      "|    critic_loss     | 3.85e+06 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 4539     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 144      |\n",
      "|    fps             | 51       |\n",
      "|    time_elapsed    | 92       |\n",
      "|    total_timesteps | 4755     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.48e+04 |\n",
      "|    critic_loss     | 3.17e+06 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 4654     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 148      |\n",
      "|    fps             | 50       |\n",
      "|    time_elapsed    | 404      |\n",
      "|    total_timesteps | 20555    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -3.7e+04 |\n",
      "|    critic_loss     | 2.11e+06 |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 20454    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    episodes        | 152      |\n",
      "|    fps             | 50       |\n",
      "|    time_elapsed    | 431      |\n",
      "|    total_timesteps | 21914    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -3.9e+04 |\n",
      "|    critic_loss     | 3.2e+06  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 21813    |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 156       |\n",
      "|    fps             | 50        |\n",
      "|    time_elapsed    | 466       |\n",
      "|    total_timesteps | 23682     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -4.09e+04 |\n",
      "|    critic_loss     | 2.19e+06  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 23581     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 160       |\n",
      "|    fps             | 51        |\n",
      "|    time_elapsed    | 567       |\n",
      "|    total_timesteps | 28957     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -4.44e+04 |\n",
      "|    critic_loss     | 1.37e+06  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 28856     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 164       |\n",
      "|    fps             | 48        |\n",
      "|    time_elapsed    | 980       |\n",
      "|    total_timesteps | 47586     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -6.22e+04 |\n",
      "|    critic_loss     | 1.26e+06  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 47485     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 168       |\n",
      "|    fps             | 47        |\n",
      "|    time_elapsed    | 1176      |\n",
      "|    total_timesteps | 56455     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -7.04e+04 |\n",
      "|    critic_loss     | 2.19e+06  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 56354     |\n",
      "----------------------------------\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ZPD\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\ZPD\\AppData\\Local\\Temp\\ipykernel_56828\\740549276.py\", line 14, in <module>\n",
      "    model.learn(total_timesteps = 100000)\n",
      "  File \"d:\\Study\\anaconda\\envs\\new\\lib\\site-packages\\stable_baselines3\\ddpg\\ddpg.py\", line 123, in learn\n",
      "    return super().learn(\n",
      "  File \"d:\\Study\\anaconda\\envs\\new\\lib\\site-packages\\stable_baselines3\\td3\\td3.py\", line 222, in learn\n",
      "    return super().learn(\n",
      "  File \"d:\\Study\\anaconda\\envs\\new\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py\", line 328, in learn\n",
      "    rollout = self.collect_rollouts(\n",
      "  File \"d:\\Study\\anaconda\\envs\\new\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py\", line 560, in collect_rollouts\n",
      "    new_obs, rewards, dones, infos = env.step(actions)\n",
      "  File \"d:\\Study\\anaconda\\envs\\new\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py\", line 206, in step\n",
      "    return self.step_wait()\n",
      "  File \"d:\\Study\\anaconda\\envs\\new\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py\", line 58, in step_wait\n",
      "    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(\n",
      "  File \"d:\\Study\\anaconda\\envs\\new\\lib\\site-packages\\gymnasium\\wrappers\\common.py\", line 125, in step\n",
      "    observation, reward, terminated, truncated, info = self.env.step(action)\n",
      "  File \"d:\\Study\\anaconda\\envs\\new\\lib\\site-packages\\gymnasium\\wrappers\\common.py\", line 393, in step\n",
      "    return super().step(action)\n",
      "  File \"d:\\Study\\anaconda\\envs\\new\\lib\\site-packages\\gymnasium\\core.py\", line 322, in step\n",
      "    return self.env.step(action)\n",
      "  File \"d:\\Study\\anaconda\\envs\\new\\lib\\site-packages\\gymnasium\\wrappers\\common.py\", line 285, in step\n",
      "    return self.env.step(action)\n",
      "  File \"c:\\Users\\ZPD\\Desktop\\GEARS\\myCartpoleF_SwingUp.py\", line 392, in step\n",
      "  File \"c:\\Users\\ZPD\\Desktop\\GEARS\\myCartpoleF_SwingUp.py\", line 507, in render\n",
      "    gfxdraw.filled_polygon(self.surf, cart_coords, (0, 0, 0))\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ZPD\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\interactiveshell.py\", line 2105, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"C:\\Users\\ZPD\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 1396, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\Users\\ZPD\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 1287, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\Users\\ZPD\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 1140, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"C:\\Users\\ZPD\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 1055, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"C:\\Users\\ZPD\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 955, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"C:\\Users\\ZPD\\AppData\\Roaming\\Python\\Python38\\site-packages\\IPython\\core\\ultratb.py\", line 778, in lines\n",
      "    return self._sd.lines\n",
      "  File \"C:\\Users\\ZPD\\AppData\\Roaming\\Python\\Python38\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"C:\\Users\\ZPD\\AppData\\Roaming\\Python\\Python38\\site-packages\\stack_data\\core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"C:\\Users\\ZPD\\AppData\\Roaming\\Python\\Python38\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"C:\\Users\\ZPD\\AppData\\Roaming\\Python\\Python38\\site-packages\\stack_data\\core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"C:\\Users\\ZPD\\AppData\\Roaming\\Python\\Python38\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"C:\\Users\\ZPD\\AppData\\Roaming\\Python\\Python38\\site-packages\\stack_data\\core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"C:\\Users\\ZPD\\AppData\\Roaming\\Python\\Python38\\site-packages\\executing\\executing.py\", line 116, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "# 步骤三：使用 DDPG 算法训练代理\n",
    "from stable_baselines3 import DDPG\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "# 将环境包装为向量环境\n",
    "env = DummyVecEnv([lambda: gym.make('CartPoleSwingUp', render_mode='human')])\n",
    "\n",
    "# 初始化 DDPG 代理\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "# 加入噪声\n",
    "action_noise = NormalActionNoise(mean = np.zeros(env.action_space.shape), sigma = 0.2 * np.ones(env.action_space.shape))\n",
    "model = DDPG('MlpPolicy', env, policy_kwargs = dict(net_arch=[256, 128]), action_noise = action_noise, verbose = 1)\n",
    "\n",
    "model.learn(total_timesteps = 100000)\n",
    "\n",
    "model.save(\"ddpg_cartpole_model\")\n",
    "# 评估训练后的模型\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "model = DDPG.load(\"ddpg_cartpole_model\")\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes = 10)\n",
    "print(f\"Mean reward: {mean_reward}, Std reward: {std_reward}\")\n",
    "\n",
    "# 测试模型\n",
    "obs = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    env.render()  # 可视化环境\n",
    "\n",
    "env.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
